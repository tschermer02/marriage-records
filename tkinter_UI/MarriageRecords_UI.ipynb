{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d2613aa-703b-4ceb-99b4-9ac5e32fd831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 8.0.129, 8.0.174, 8.0.177\n",
      "ERROR: Ignored the following versions that require a different python version: 8.0.10 Requires-Python >=3.7,<=3.11; 8.0.11 Requires-Python >=3.7,<=3.11; 8.0.12 Requires-Python >=3.7,<=3.11; 8.0.13 Requires-Python >=3.7,<=3.11; 8.0.14 Requires-Python >=3.7,<=3.11; 8.0.15 Requires-Python >=3.7,<=3.11; 8.0.16 Requires-Python >=3.7,<=3.11; 8.0.17 Requires-Python >=3.7,<=3.11; 8.0.18 Requires-Python >=3.7,<=3.11; 8.0.19 Requires-Python >=3.7,<=3.11; 8.0.20 Requires-Python >=3.7,<=3.11; 8.0.21 Requires-Python >=3.7,<=3.11; 8.0.22 Requires-Python >=3.7,<=3.11; 8.0.23 Requires-Python >=3.7,<=3.11; 8.0.24 Requires-Python >=3.7,<=3.11; 8.0.25 Requires-Python >=3.7,<=3.11; 8.0.26 Requires-Python >=3.7,<=3.11; 8.0.27 Requires-Python >=3.7,<=3.11; 8.0.28 Requires-Python >=3.7,<=3.11; 8.0.29 Requires-Python >=3.7,<=3.11; 8.0.30 Requires-Python >=3.7,<=3.11; 8.0.31 Requires-Python >=3.7,<=3.11; 8.0.32 Requires-Python >=3.7,<=3.11; 8.0.33 Requires-Python >=3.7,<=3.11; 8.0.34 Requires-Python >=3.7,<=3.11; 8.0.7 Requires-Python >=3.7,<=3.11; 8.0.8 Requires-Python >=3.7,<=3.11; 8.0.9 Requires-Python >=3.7,<=3.11\n",
      "ERROR: Could not find a version that satisfies the requirement ultralytics==8.0.20 (from versions: 0.0.13, 0.0.14, 0.0.15, 0.0.16, 0.0.17, 0.0.18, 0.0.19, 0.0.20, 0.0.21, 0.0.22, 0.0.23, 0.0.24, 0.0.25, 0.0.26, 0.0.27, 0.0.28, 0.0.29, 0.0.30, 0.0.31, 0.0.32, 0.0.33, 0.0.34, 0.0.35, 0.0.36, 0.0.37, 0.0.38, 0.0.39, 0.0.40, 0.0.41, 0.0.42, 0.0.43, 0.0.44, 8.0.0, 8.0.1, 8.0.2, 8.0.3, 8.0.4, 8.0.5, 8.0.6, 8.0.35, 8.0.36, 8.0.37, 8.0.38, 8.0.39, 8.0.40, 8.0.41, 8.0.42, 8.0.43, 8.0.44, 8.0.45, 8.0.46, 8.0.47, 8.0.48, 8.0.49, 8.0.50, 8.0.51, 8.0.52, 8.0.53, 8.0.54, 8.0.55, 8.0.56, 8.0.57, 8.0.58, 8.0.59, 8.0.60, 8.0.61, 8.0.62, 8.0.63, 8.0.64, 8.0.65, 8.0.66, 8.0.67, 8.0.68, 8.0.69, 8.0.70, 8.0.71, 8.0.72, 8.0.73, 8.0.74, 8.0.75, 8.0.76, 8.0.77, 8.0.78, 8.0.79, 8.0.80, 8.0.81, 8.0.82, 8.0.83, 8.0.84, 8.0.85, 8.0.86, 8.0.87, 8.0.88, 8.0.89, 8.0.90, 8.0.91, 8.0.92, 8.0.93, 8.0.94, 8.0.95, 8.0.96, 8.0.97, 8.0.98, 8.0.99, 8.0.100, 8.0.101, 8.0.102, 8.0.103, 8.0.104, 8.0.105, 8.0.106, 8.0.107, 8.0.108, 8.0.109, 8.0.110, 8.0.111, 8.0.112, 8.0.113, 8.0.114, 8.0.115, 8.0.116, 8.0.117, 8.0.118, 8.0.119, 8.0.120, 8.0.121, 8.0.122, 8.0.123, 8.0.124, 8.0.125, 8.0.126, 8.0.127, 8.0.128, 8.0.130, 8.0.131, 8.0.132, 8.0.133, 8.0.134, 8.0.135, 8.0.136, 8.0.137, 8.0.138, 8.0.139, 8.0.140, 8.0.141, 8.0.142, 8.0.143, 8.0.144, 8.0.145, 8.0.146, 8.0.147, 8.0.148, 8.0.149, 8.0.150, 8.0.151, 8.0.152, 8.0.153, 8.0.154, 8.0.155, 8.0.156, 8.0.157, 8.0.158, 8.0.159, 8.0.160, 8.0.161, 8.0.162, 8.0.163, 8.0.164, 8.0.165, 8.0.166, 8.0.167, 8.0.168, 8.0.169, 8.0.170, 8.0.171, 8.0.172, 8.0.173, 8.0.175, 8.0.176, 8.0.178, 8.0.179, 8.0.180, 8.0.181, 8.0.182, 8.0.183, 8.0.184, 8.0.185, 8.0.186, 8.0.187, 8.0.188, 8.0.189, 8.0.190, 8.0.191, 8.0.192, 8.0.193, 8.0.194, 8.0.195, 8.0.196, 8.0.197, 8.0.198, 8.0.199, 8.0.200, 8.0.201, 8.0.202, 8.0.203, 8.0.204, 8.0.205, 8.0.206, 8.0.207, 8.0.208, 8.0.209, 8.0.210, 8.0.211, 8.0.212, 8.0.213, 8.0.214, 8.0.215, 8.0.216, 8.0.217, 8.0.218, 8.0.219, 8.0.220, 8.0.221, 8.0.222, 8.0.223, 8.0.224, 8.0.225, 8.0.226, 8.0.227)\n",
      "ERROR: No matching distribution found for ultralytics==8.0.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics==8.0.20 -q\n",
    "%pip install pyyaml -q\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, Image\n",
    "from IPython import display\n",
    "import yaml\n",
    "\n",
    "import time\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c46afd0-4f66-40da-b175-ae4199f1d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsche\\source\\repos\\marriage-records\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file datasets already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.12)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.26.1)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: supervision in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (0.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (4.43.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->roboflow) (3.3.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from supervision->roboflow) (1.11.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.222, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in MR-8 to yolov8:: 100%|██████████| 21200/21200 [00:01<00:00, 14505.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to MR-8 in yolov8:: 100%|██████████| 509/509 [00:00<00:00, 2374.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsche\\source\\repos\\marriage-records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir datasets\n",
    "%cd datasets\n",
    "\n",
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"9ubavwmtSsc3S8XChm2T\")\n",
    "project = rf.workspace(\"marrigerecordprocessing\").project(\"mr-jfydd\")\n",
    "dataset = project.version(8).download(\"yolov8\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c11565-720d-4198-9864-4cd3237769ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"best (4).pt\")\n",
    "\n",
    "def createTestModel(image_name):\n",
    "  # Using with Python SDK\n",
    "  img_src = image_name\n",
    "  model.predict(img_src, save = True, save_txt = True)\n",
    "  display.clear_output()\n",
    "\n",
    "  # Using with CLI\n",
    "  !yolo task=detect mode=predict model=yolov8s.pt conf=0.25 source=image_name save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af2882f-07fa-479b-82b3-cc4181737b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tk in c:\\users\\tsche\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file test_image_folder already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsche\\source\\repos\\marriage-records\\test_image_folder\n",
      "c:\\Users\\tsche\\source\\repos\\marriage-records\n",
      "c:\\Users\\tsche\\source\\repos\\marriage-records\\test_image_folder\n",
      "c:\\Users\\tsche\\source\\repos\\marriage-records\n"
     ]
    }
   ],
   "source": [
    "%pip install tk\n",
    "\n",
    "import shutil\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk \n",
    "\n",
    "%mkdir test_image_folder \n",
    "\n",
    "# Function to open files\n",
    "def open_files():\n",
    "    filenames = filedialog.askopenfilenames(\n",
    "    # Defining the file types\n",
    "    filetypes=(\n",
    "    (\"Images\", (\"*.JPG\", \"*.JPEG\")),)\n",
    "    ) \n",
    "        \n",
    "    # Displaying Image\n",
    "    image_path = filenames[0]\n",
    "    image = Image.open(image_path)\n",
    "    photo = image.resize((300, 400), Image.Resampling.LANCZOS)\n",
    "    photo = ImageTk.PhotoImage(photo)\n",
    "    image_label.photo = photo\n",
    "    image_label.config(image=photo)\n",
    "    \n",
    "# Accessing names for the selected files\n",
    "    for filename in filenames:\n",
    "        Label(root, text = filename).pack(side = TOP)\n",
    "        # Finding the path of the test image directory\n",
    "        %cd test_image_folder       \n",
    "        new_path = os.getcwd()\n",
    "        %cd .. \n",
    "        # Moving images into the test image directory\n",
    "        shutil.move(filename, new_path)    \n",
    "\n",
    "# Main UI\n",
    "root = Tk()\n",
    "# Size of pop-up window\n",
    "root.geometry(\"800x800\")\n",
    "# Pop-up window title\n",
    "root.title(\"Batch Document Processor\")\n",
    "\n",
    "# Displaying Button\n",
    "button = Button(root, text = \"Select files\", command = open_files)\n",
    "# Location of the button\n",
    "button.pack(side = BOTTOM, pady = 30)\n",
    "\n",
    "# Displaying Image/Result\n",
    "image_label = Label(root)\n",
    "image_label.pack(side = TOP)\n",
    "\n",
    "# Loop for pop-up window until closed\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaad099a-c267-41ef-b6e0-73e7fbc907eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.222 🚀 Python-3.11.1 torch-2.1.1+cpu CPU (12th Gen Intel Core(TM) i7-1255U)\n",
      "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients, 28.6 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 448, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 239, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 207, in predict_cli\n",
      "    for _ in gen:  # running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 240, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 215, in setup_source\n",
      "    self.dataset = load_inference_source(source=source,\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\data\\build.py\", line 172, in load_inference_source\n",
      "    dataset = LoadImages(source, imgsz=imgsz, vid_stride=vid_stride)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\data\\loaders.py\", line 292, in __init__\n",
      "    raise FileNotFoundError(f'{p} does not exist')\n",
      "FileNotFoundError: image_name does not exist\n"
     ]
    }
   ],
   "source": [
    "%cd test_image_folder\n",
    "test_image_folder = os.getcwd()\n",
    "%cd ..\n",
    "\n",
    "imagePath = []\n",
    "\n",
    "for filename in os.listdir(test_image_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join (test_image_folder, filename)\n",
    "        imagePath.append(image_path)\n",
    "        createTestModel(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afcaa72f-59b8-44ab-b892-c7fcb22d2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the bounding boxes\n",
    "def cropImage(j, crop_name, img, top_left, bottom_right):\n",
    "    # Cropping an image\n",
    "    img_crop = img[top_left[j][1]:bottom_right[j][1], top_left[j][0]:bottom_right[j][0]]\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(\"croppedImages\"):\n",
    "        os.makedirs(\"croppedImages\")\n",
    "\n",
    "    error_image = cv2.imread(\"error_handle_pic.jpg\")\n",
    "\n",
    "    if img_crop.any() == False:\n",
    "      cv2.imwrite(os.path.join(\"croppedImages\", crop_name), error_image)\n",
    "    else:\n",
    "      # Save the cropped image to the specified folder\n",
    "      cv2.imwrite(os.path.join(\"croppedImages\", crop_name), img_crop)\n",
    "\n",
    "def makeBox(name, j, color, lines, top_left, bottom_right, img):\n",
    "  #print(name, j)\n",
    "  index = int(lines[j].split()[0])\n",
    "  img_d = cv2.rectangle(img, top_left[j], bottom_right[j], color,2)\n",
    "\n",
    "def extractBox(number, name, j, color, lines, top_left, bottom_right, img, crop_name):\n",
    "  if (name == number): # making boxes for milleottocentosettanta\n",
    "    makeBox(name,j, color,lines, top_left, bottom_right, img)\n",
    "    cropImage(j,crop_name, img, top_left, bottom_right)\n",
    "\n",
    "def title_extract_to_file(number):\n",
    "  title_file = [file for file in os.listdir(\"titles_folder\") if file.lower().endswith('.jpg')]\n",
    "  image_files = sorted(image_files)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hconcat_resize(img_list, interpolation=cv2.INTER_CUBIC):\n",
    "    # Resize images to have the same height (assumes images have the same width)\n",
    "    img_list_resized = [cv2.resize(img, (img_list[0].shape[1], img_list[0].shape[0]), interpolation=interpolation)\n",
    "                        for img in img_list]\n",
    "\n",
    "    # Concatenate images horizontally\n",
    "    return cv2.hconcat(img_list_resized)\n",
    "\n",
    "def h_concatenate_and_save():\n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = [file for file in os.listdir(\"croppedImages\") if file.lower().endswith('.jpg')]\n",
    "    image_files = sorted(image_files)\n",
    "\n",
    "    # Read images from the folder\n",
    "    images = [cv2.imread(os.path.join(\"croppedImages\", img)) for img in image_files]\n",
    "\n",
    "\n",
    "    # Horizontally concatenate all the images\n",
    "    img_out_put = hconcat_resize(images)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    output_folder = \"hConcatImages\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Generate output file name based on current timestamp\n",
    "    timestamp = int(time.time())\n",
    "    output_file = f\"concatenated_{timestamp}.jpg\"  # Unique filename based on timestamp\n",
    "\n",
    "    # Save the concatenated image to the output folder\n",
    "    cv2.imwrite(os.path.join(output_folder, output_file), img_out_put)\n",
    "\n",
    "def h_concatenate_and_save_for_titles():\n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = [file for file in os.listdir(\"titles_folder\") if file.lower().endswith('.jpg')]\n",
    "    image_files = sorted(image_files)\n",
    "\n",
    "\n",
    "    # Read images from the folder\n",
    "    images = [cv2.imread(os.path.join(\"titles_folder\", img)) for img in image_files]\n",
    "\n",
    "    # Horizontally concatenate all the images\n",
    "    img_out_put = hconcat_resize(images)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    output_folder = \"vConcatImages\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Generate output file name based on current timestamp\n",
    "    timestamp = int(time.time())\n",
    "    output_file = f\"concatenated_{timestamp}.jpg\"  # Unique filename based on timestamp\n",
    "\n",
    "    # Save the concatenated image to the output folder\n",
    "    cv2.imwrite(os.path.join(output_folder, output_file), img_out_put)\n",
    "\n",
    "def vconcat_resize(img_list, interpolation = cv2.INTER_CUBIC):\n",
    "    # take minimum width\n",
    "    w_min = min(img.shape[1] for img in img_list)\n",
    "    # resizing images\n",
    "    im_list_resize = [cv2.resize(img,(w_min, int(img.shape[0] * w_min / img.shape[1])),interpolation = interpolation) for img in img_list]\n",
    "    # return final image\n",
    "    return cv2.vconcat(im_list_resize)\n",
    "\n",
    "def v_concatenate_and_save():\n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = [file for file in os.listdir(\"hConcatImages\") if file.lower().endswith('.jpg')]\n",
    "    image_files = sorted(image_files)\n",
    "\n",
    "\n",
    "    # Read images from the folder\n",
    "    images = [cv2.imread(os.path.join(\"hConcatImages\", img)) for img in image_files]\n",
    "\n",
    "    # Horizontally concatenate all the images\n",
    "    img_out_put = vconcat_resize(images)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    output_folder = \"vConcatImages\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Generate output file name based on current timestamp\n",
    "    timestamp = int(time.time())\n",
    "    output_file = f\"v_concatenated_{timestamp}.jpg\"  # Unique filename based on timestamp\n",
    "\n",
    "    # Save the concatenated image to the output folder\n",
    "    cv2.imwrite(os.path.join(output_folder, output_file), img_out_put)\n",
    "\n",
    "def final_v_concatenate_and_save():\n",
    "    # Get a list of image files in the input folder\n",
    "    image_files = [file for file in os.listdir(\"vConcatImages\") if file.lower().endswith('.jpg')]\n",
    "    image_files = sorted(image_files)\n",
    "\n",
    "\n",
    "    # Read images from the folder\n",
    "    images = [cv2.imread(os.path.join(\"vConcatImages\", img)) for img in image_files]\n",
    "\n",
    "    # Horizontally concatenate all the images\n",
    "    img_out_put = vconcat_resize(images)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    output_folder = \"finalvConcatImages\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Generate output file name based on current timestamp\n",
    "    timestamp = int(time.time())\n",
    "    output_file = f\"v_concatenated_{timestamp}.jpg\"  # Unique filename based on timestamp\n",
    "\n",
    "    # Save the concatenated image to the output folder\n",
    "    cv2.imwrite(os.path.join(output_folder, output_file), img_out_put)\n",
    "\n",
    "  # Clear contents of hConcatImages folder\n",
    "def clear_hconcat_images_folder():\n",
    "    folder_path = \"hConcatImages\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove all files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' folder does not exist.\")\n",
    "\n",
    "  # Clear contents of vConcatImages folder\n",
    "def clear_vconcat_images_folder():\n",
    "    folder_path = \"vConcatImages\"\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove all files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' folder does not exist.\")\n",
    "\n",
    "def testModel(input_folder_images, input_folder_labels, output_folder):\n",
    "\n",
    "    image_files = os.listdir(input_folder_images)\n",
    "    image_files = sorted(image_files)\n",
    "\n",
    "    label_files = os.listdir(input_folder_labels)\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_name, img_ext = os.path.splitext(img_file)\n",
    "        corresponding_label = next((label for label in label_files if label.startswith(img_name)), None)\n",
    "\n",
    "        if corresponding_label:\n",
    "            img_path = os.path.join(input_folder_images, img_file)\n",
    "            label_path = os.path.join(input_folder_labels, corresponding_label)\n",
    "\n",
    "             # Interpreting the results\n",
    "            file_name = \"datasets/MR-8/data.yaml\"\n",
    "            with open(file_name, \"r\") as stream:\n",
    "              names = yaml.safe_load(stream)[\"names\"]\n",
    "            with open(label_path, \"r\") as label_file:\n",
    "                lines = label_file.readlines()\n",
    "            print(names); print(lines)\n",
    "\n",
    "            top_left = [0]*len(lines)\n",
    "            bottom_right = [0]*len(lines)\n",
    "\n",
    "            temp_1 = [0]*len(lines)\n",
    "            temp_2 = [0]*len(lines)\n",
    "\n",
    "            lines.sort(key = lambda x: (x[1], x[2]))\n",
    "\n",
    "            #Blue boxes for data\n",
    "            for i in range(len(lines)):\n",
    "\n",
    "              index = int(lines[i].split()[0])\n",
    "\n",
    "              obj = lines[i].split()\n",
    "              xc, yc, nw, nh = float(obj[1]), float(obj[2]), float(obj[3]), float(obj[4])\n",
    "              # xc, yc are normalized center coordinates, nw and nh are normalized height and width\n",
    "\n",
    "              img = cv2.imread(img_path)\n",
    "              h, w = img.shape[0], img.shape[1]\n",
    "              xc *= w; yc *= h; nw *= w; nh *= h\n",
    "\n",
    "              # Grabing millocen,1,nato in,residente,2,nata in,residente, anni, di\n",
    "\n",
    "              if (index == 11): # milleottocentosettanta bounding box\n",
    "                top_left[i] = int(xc - nw/2+295), int(yc - nh/2-25); bottom_right[i] = int(xc + nw/2+200), int(yc + nh/2+10)\n",
    "\n",
    "              if (index == 13): # nata in bounding box.\n",
    "                top_left[i] = int(xc - nw/2+100), int(yc - nh/2-25); bottom_right[i] = int(xc + nw/2+300), int(yc + nh/2+10)\n",
    "\n",
    "              if (index == 0): # 2 bounding box.\n",
    "                top_left[i] = int(xc - nw/2+40), int(yc - nh/2-15); bottom_right[i] = int(xc + nw/2+625), int(yc + nh/2+15)\n",
    "\n",
    "              if (index == 19): # residente bounding box\n",
    "                temp_1[i] = int(xc - nw/2), int(yc - nh/2); temp_2[i] = int(xc + nw/2), int(yc + nh/2)\n",
    "                #highest residente\n",
    "                if((((600 < temp_2[i][0] and temp_2[i][0] < 725) and (700 < temp_2[i][1] and temp_2[i][1] < 880)))):\n",
    "                  top_left[i] = int(xc - nw/2+180), int(yc - nh/2-25); bottom_right[i] = int(xc + nw/2+300), int(yc + nh/2+10)\n",
    "\n",
    "                elif((((1500 < temp_2[i][0] and temp_2[i][0] < 2150) and (700 < temp_2[i][1] and temp_2[i][1] < 880)))):\n",
    "                  top_left[i] = int(xc - nw/2+180), int(yc - nh/2-25); bottom_right[i] = int(xc + nw/2+300), int(yc + nh/2+10)\n",
    "\n",
    "                # shifted residente.\n",
    "                elif((((1220 < temp_2[i][0] and temp_2[i][0] < 1400) and (870 < temp_2[i][1] and temp_2[i][1] < 1125))) and temp_1[i][0] > 1000):\n",
    "                  top_left[i] = int(xc - nw/2-1100), int(yc - nh/2+45); bottom_right[i] = int(xc + nw/2-950), int(yc + nh/2+80)\n",
    "\n",
    "                elif((((2100 < temp_2[i][0] and temp_2[i][0] < 2300) and (870 < temp_2[i][1] and temp_2[i][1] < 1125))) and temp_1[i][0] > 1500):\n",
    "                  top_left[i] = int(xc - nw/2-1100), int(yc - nh/2+45); bottom_right[i] = int(xc + nw/2-950), int(yc + nh/2+80)\n",
    "\n",
    "                else:\n",
    "                  top_left[i] = 0,0; bottom_right[i] = 0,0\n",
    "\n",
    "              if (index == 7): # figlia d bounding box, this for right now is to grab residente.\n",
    "                top_left[i] = int(xc - nw/2-300), int(yc - nh/2-15); bottom_right[i] = int(xc + nw/2-125), int(yc + nh/2+15)\n",
    "\n",
    "              if (index == 8): # fidlio d bounding box, this for right now is to grab residente.\n",
    "                top_left[i] = int(xc - nw/2-300), int(yc - nh/2-15); bottom_right[i] = int(xc + nw/2-125), int(yc + nh/2+15)\n",
    "\n",
    "              if (index == 14): # nato in bounding box\n",
    "                top_left[i] = int(xc - nw/2+100), int(yc - nh/2-25); bottom_right[i] = int(xc + nw/2+300), int(yc + nh/2+10)\n",
    "\n",
    "              if (index == 9): # l bounding box\n",
    "                top_left[i] = int(xc - nw/2+40), int(yc - nh/2-25); bottom_right[i] = int(xc + nw/2+550), int(yc + nh/2+15)\n",
    "\n",
    "              if (index == 3): # addi bounding box\n",
    "                top_left[i] = int(xc - nw/2+75), int(yc - nh/2-15); bottom_right[i] = int(xc + nw/2+200), int(yc + nh/2+15)\n",
    "\n",
    "\n",
    "              if (index == 4): # anni bounding box\n",
    "                temp_1[i] = int(xc - nw/2), int(yc - nh/2); temp_2[i] = int(xc + nw/2), int(yc + nh/2)\n",
    "\n",
    "                # first anni\n",
    "                if((((1000 < temp_2[i][0] and temp_2[i][0] < 2000) and (550 < temp_2[i][1] and temp_2[i][1] < 840)))):\n",
    "                  top_left[i] = int(xc - nw/2+70), int(yc - nh/2-20); bottom_right[i] = int(xc + nw/2+210), int(yc + nh/2+10)\n",
    "\n",
    "                elif((((600 < temp_2[i][0] and temp_2[i][0] < 950) and (550 < temp_2[i][1] and temp_2[i][1] < 840)))):\n",
    "                  top_left[i] = int(xc - nw/2+70), int(yc - nh/2-20); bottom_right[i] = int(xc + nw/2+210), int(yc + nh/2+10)\n",
    "\n",
    "                # second anni\n",
    "                elif((((850 < temp_2[i][0] and temp_2[i][0] < 1300) and (800 < temp_2[i][1] and temp_2[i][1] < 1100)))):\n",
    "                  top_left[i] = int(xc - nw/2+70), int(yc - nh/2-20); bottom_right[i] = int(xc + nw/2+210), int(yc + nh/2+10)\n",
    "\n",
    "                elif((((50 < temp_2[i][0] and temp_2[i][0] < 500) and (800 < temp_2[i][1] and temp_2[i][1] < 1100)))):\n",
    "                  top_left[i] = int(xc - nw/2+70), int(yc - nh/2-20); bottom_right[i] = int(xc + nw/2+210), int(yc + nh/2+10)\n",
    "\n",
    "                # last two anni\n",
    "                else:\n",
    "                  top_left[i] = 0,0; bottom_right[i] = 0,0\n",
    "\n",
    "           #Grabbing the first di\n",
    "              if(index == 5):\n",
    "                temp_1[i] = int(xc - nw/2), int(yc - nh/2); temp_2[i] = int(xc + nw/2), int(yc + nh/2)\n",
    "\n",
    "                if((((2000 < temp_2[i][0] and temp_2[i][0] < 3000) and (100 < temp_2[i][1] and temp_2[i][1] < 500)))):\n",
    "                  top_left[i] = int(xc - nw/2+50), int(yc - nh/2-15); bottom_right[i] = int(xc + nw/2+200), int(yc + nh/2+15)\n",
    "\n",
    "                elif((((1000 < temp_2[i][0] and temp_2[i][0] < 2500) and (100 < temp_2[i][1] and temp_2[i][1] < 500)))):\n",
    "                  top_left[i] = int(xc - nw/2+50), int(yc - nh/2-15); bottom_right[i] = int(xc + nw/2+200), int(yc + nh/2+15)\n",
    "\n",
    "                else:\n",
    "                  top_left[i] = 0,0; bottom_right[i] = 0,0\n",
    "\n",
    "\n",
    "            for j in range(len(lines)):\n",
    "              name =lines[j].split()[0]\n",
    "\n",
    "              # making boxes for milleottocentosettanta\n",
    "              extractBox('11', name, j, (0,255,0), lines, top_left, bottom_right, img, \"7_millo_year.jpg\")\n",
    "\n",
    "              # making boxes for nata in\n",
    "              #extractBox('13', name, j, (255, 0, 127), lines, top_left, bottom_right, img, \"13_HW.jpg\")\n",
    "\n",
    "              # making boxes for 2\n",
    "              extractBox('0', name, j, (0, 0, 255), lines, top_left, bottom_right, img, \"1_husband_name.jpg\")\n",
    "\n",
    "              # making boxes for residente\n",
    "              #highest residente\n",
    "              if (name == '19'):\n",
    "                bottom_x = bottom_right[j][0]\n",
    "                bottom_y = bottom_right[j][1]\n",
    "                top_x = top_left[j][0]\n",
    "\n",
    "                if((((975 < bottom_x and bottom_x < 1010) and (800 < bottom_y and bottom_y < 875)))):\n",
    "                  extractBox('19', name, j, (255, 255, 0), lines, top_left, bottom_right, img, \"3_husband_res.jpg\")\n",
    "\n",
    "                elif((((1800 < bottom_x and bottom_x < 2450) and (750 < bottom_y and bottom_y < 900)))and top_x >1500 and top_x<2150):\n",
    "                  extractBox('19', name, j, (255, 255, 0), lines, top_left, bottom_right, img, \"3_husband_res.jpg\")\n",
    "\n",
    "                # shifted residente.\n",
    "                elif((((275 < bottom_x and bottom_x < 425) and (1000 < bottom_y and bottom_y < 1150))) and top_x < 100):\n",
    "                  extractBox('19', name, j, (255, 255, 0), lines, top_left, bottom_right, img, \"6_wife_res.jpg\")\n",
    "\n",
    "                elif((((1100 < bottom_x and bottom_x < 1350) and (1000 < bottom_y and bottom_y < 1150))) and top_x > 800):\n",
    "                  extractBox('19', name, j, (255, 255, 0), lines, top_left, bottom_right, img, \"6_wife_res.jpg\")\n",
    "\n",
    "              # making boxes for l\n",
    "              extractBox('9', name, j, (0, 0, 255), lines, top_left, bottom_right, img, \"4_wife_name.jpg\")\n",
    "\n",
    "              # making boxes for addi\n",
    "              extractBox('3', name, j, (255, 0, 255), lines, top_left, bottom_right, img, \"8_addi_.jpg\")\n",
    "\n",
    "              #highest anni\n",
    "              if (name == '4'):\n",
    "                bottom_x = bottom_right[j][0]\n",
    "                bottom_y = bottom_right[j][1]\n",
    "                top_x = top_left[j][0]\n",
    "\n",
    "                if((((50 < bottom_x and bottom_x < 3000) and (400 < bottom_y and bottom_y < 900)))):\n",
    "                  extractBox('4', name, j, (0, 200, 250), lines, top_left, bottom_right, img, \"2_anni_husband_age.jpg\")\n",
    "\n",
    "                # second anni\n",
    "                elif((((50 < bottom_x and bottom_x < 1500) and (900 < bottom_y and bottom_y < 2150)))):\n",
    "                  extractBox('4', name, j, (0, 200, 250), lines, top_left, bottom_right, img, \"5_anni_wife_age.jpg\")\n",
    "\n",
    "              #The first di\n",
    "              if(name == '5'):\n",
    "                bottom_x = bottom_right[j][0]\n",
    "                bottom_y = bottom_right[j][1]\n",
    "                top_x = top_left[j][0]\n",
    "\n",
    "                if((((2000 < bottom_x and bottom_x < 3000) and (100 < bottom_y and bottom_y < 400)))):\n",
    "                  extractBox('5', name, j,(165, 42, 42), lines, top_left, bottom_right, img, \"9_di_month.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Generate the output file name based on the image file name or other criteria\n",
    "            output_file = f\"{img_name}_processed{img_ext}\"  # Adjust as needed\n",
    "\n",
    "            h_concatenate_and_save()\n",
    "\n",
    "\n",
    "            # Save or do further processing with the result\n",
    "            output_path = os.path.join(output_folder, output_file)\n",
    "            # cv2.imwrite(output_path, processed_image)  # Save the processed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e01634b-6603-49b3-8ec1-746f8b2b988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', 'Avanti di me', 'Numero', 'addi', 'anni', 'di', 'e d', 'figlia d', 'figlio d', 'l', 'meridiane', 'milleottocentosettanta', 'minuti', 'nata', 'nato in', 'ore', 'presentat', 'presente', 'presenti', 'residente']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['4 0.343515 0.582254 0.0455465 0.0110945\\n', '11 0.174534 0.106814 0.143511 0.0120022\\n', '12 0.312823 0.12637 0.0526588 0.0122498\\n', '4 0.334345 0.602928 0.0346036 0.0111634\\n', '4 0.389082 0.223821 0.0327043 0.0105798\\n', '2 0.72331 0.107534 0.0729294 0.0170134\\n', '19 0.181994 0.262872 0.0886494 0.0117046\\n', '19 0.279121 0.244795 0.0836919 0.0118947\\n', '19 0.367649 0.345616 0.0815578 0.0103496\\n', '19 0.452741 0.324997 0.0871221 0.0112015\\n', '10 0.160762 0.127522 0.0677277 0.0118184\\n', '3 0.358404 0.105632 0.0366902 0.0124345\\n', '19 0.576153 0.305483 0.0814738 0.0116703\\n', '8 0.494839 0.245821 0.0511499 0.0128235\\n', '5 0.496418 0.106013 0.0207053 0.0119391\\n', '7 0.203012 0.322924 0.0522719 0.0111982\\n', '6 0.0560474 0.343937 0.0311026 0.0107397\\n', '19 0.0806279 0.283702 0.079412 0.0105595\\n', '14 0.0687435 0.245885 0.0529161 0.0109975\\n', '13 0.38353 0.303773 0.0503399 0.0113017\\n', '4 0.0677555 0.302645 0.0447734 0.0104005\\n', '0 0.306314 0.282374 0.0216225 0.0105112\\n', '5 0.0550985 0.144909 0.0204731 0.0102519\\n', '9 0.0533906 0.225607 0.0211382 0.0106668\\n', '15 0.068506 0.127789 0.0304314 0.00982566\\n', '1 0.0960001 0.16334 0.0904151 0.0109095\\n']\n",
      "['2', 'Avanti di me', 'Numero', 'addi', 'anni', 'di', 'e d', 'figlia d', 'figlio d', 'l', 'meridiane', 'milleottocentosettanta', 'minuti', 'nata', 'nato in', 'ore', 'presentat', 'presente', 'presenti', 'residente']\n",
      "['19 0.557613 0.264418 0.08058 0.011694\\n', '3 0.715471 0.110296 0.0315789 0.0123434\\n', '19 0.80821 0.324308 0.0817249 0.0114435\\n', '1 0.478911 0.166682 0.0827028 0.0114909\\n', '7 0.580776 0.324659 0.0512519 0.0125879\\n', '19 0.466435 0.285868 0.0745724 0.0114329\\n', '2 0.25576 0.111786 0.0662815 0.0164058\\n', '11 0.549063 0.111575 0.139497 0.0119091\\n', '19 0.648832 0.24689 0.075839 0.0117312\\n', '14 0.453324 0.247892 0.0470254 0.0112382\\n', '10 0.534651 0.131702 0.0651349 0.0109966\\n', '4 0.699013 0.601228 0.0343197 0.0114464\\n', '15 0.452062 0.132796 0.0277704 0.0101578\\n', '8 0.844817 0.244777 0.0478728 0.0118136\\n', '19 0.730239 0.345066 0.0770132 0.0118265\\n', '5 0.440922 0.149058 0.017835 0.0101944\\n', '4 0.459512 0.304849 0.0330712 0.0116381\\n', '19 0.919821 0.30359 0.0730389 0.0117872\\n', '9 0.440252 0.226883 0.0170334 0.0119163\\n', '4 0.712127 0.580493 0.0334957 0.0120809\\n', '6 0.444014 0.345545 0.0319043 0.0113873\\n', '12 0.674245 0.130373 0.0488221 0.0125232\\n', '0 0.670291 0.284072 0.0164176 0.0108978\\n', '13 0.742817 0.303752 0.0449511 0.0108219\\n', '5 0.842449 0.107651 0.0186099 0.0114151\\n']\n"
     ]
    }
   ],
   "source": [
    "# Clear the contents of hConcatImages folder before running the code\n",
    "clear_hconcat_images_folder()\n",
    "clear_vconcat_images_folder()\n",
    "testModel(\"test_image_folder\",\"predict/dataset/labels\", \"testModel_image\")\n",
    "\n",
    "v_concatenate_and_save()\n",
    "h_concatenate_and_save_for_titles()\n",
    "final_v_concatenate_and_save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c160ae-a686-4e66-a0af-5ea16a604894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.227 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.222 🚀 Python-3.11.1 torch-2.1.1+cpu CPU (12th Gen Intel Core(TM) i7-1255U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=c:\\Users\\tsche\\source\\repos\\marriage-records\\datasets\\MR-8/data.yaml, epochs=200, patience=500, batch=32, imgsz=800, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\tsche\\runs\\detect\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 116, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 312, in check_det_dataset\n",
      "    raise FileNotFoundError(m)\n",
      "FileNotFoundError: \n",
      "Dataset 'c://Users/tsche/source/repos/marriage-records/datasets/MR-8/data.yaml' images not found ⚠️, missing path 'C:\\Users\\tsche\\source\\repos\\marriage-records\\datasets\\MR-8\\MR-8\\valid\\images'\n",
      "Note dataset download directory is 'C:\\Users\\datasets'. You can update this in 'C:\\Users\\tsche\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 448, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 333, in train\n",
      "    self.trainer = (trainer or self._smart_load('trainer'))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 120, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\")) from e\n",
      "RuntimeError: Dataset 'c://Users/tsche/source/repos/marriage-records/datasets/MR-8/data.yaml' error  \n",
      "Dataset 'c://Users/tsche/source/repos/marriage-records/datasets/MR-8/data.yaml' images not found , missing path 'C:\\Users\\tsche\\source\\repos\\marriage-records\\datasets\\MR-8\\MR-8\\valid\\images'\n",
      "Note dataset download directory is 'C:\\Users\\datasets'. You can update this in 'C:\\Users\\tsche\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs= 200 imgsz=800 plots=True batch = 32 patience = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ae0099f-5259-48e3-a9c6-b51776f983d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 423, in entrypoint\n",
      "    model = YOLO(model, task=task)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 94, in __init__\n",
      "    self._load(model, task)\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 146, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 628, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 567, in torch_safe_load\n",
      "    return torch.load(file, map_location='cpu'), file  # load\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 986, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 435, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 416, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'runs\\\\detect\\\\train3\\\\weights\\\\best.pt'\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "!yolo task=detect mode=predict model=runs/detect/train3/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14c833d8-6a0d-48aa-95b7-6621b6f4a7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 423, in entrypoint\n",
      "    model = YOLO(model, task=task)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 94, in __init__\n",
      "    self._load(model, task)\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 146, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 628, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 567, in torch_safe_load\n",
      "    return torch.load(file, map_location='cpu'), file  # load\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 986, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 435, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tsche\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py\", line 416, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'runs\\\\detect\\\\train\\\\weights\\\\best.pt'\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
